# COURSERA

## Теория вероятности
* Условная вероятность
* Формала полной вероятности
* Формула Байеса

## Статистика
* СЛучайная величина
* Функция вероятности
* Плотность распределения
* Метод максимального правдоподобия
* Метод Ньютона

Описание всех распределений:
https://habr.com/ru/post/311092/

* Функция распределения и плотность вероятности непрерывной случайной величины, их взаимосвязь и свойства
https://studopedia.su/5_61389_funktsiya-raspredeleniya-i-plotnost-veroyatnosti-neprerivnoy-sluchaynoy-velichini-ih-vzaimosvyaz-i-svoystva.html
* виды распределений (паусано биномиальное лапласса  бернули и т д )
* np полная задача
* EM алгоритмы 
* остовное дерево - графы

КАРТА РАСПРЕДЕЛЕНИЙ!!! 15 типов распределений
https://blog.kinetica.su/osnovy_statistiki_dlya_veb-analitika_15_tipov_raspredeleniya_veroyatnostej/

алгоритмы направленного поиска
нахождение градинта функций x2 на листочке 
производная по первой компаненте и по второй на листочке

z и t статистика
кореляция и ковариация 

logloss Логистичсекая функция потерь
https://ai-news.ru/2019/04/logisticheskaya_funkciya_oshibki.html


Требования
Знание алгоритмов Catboost, LightGBM, Xgboost

EM algorithms 
Meanshift alg
CatBoost
LightGBM

categorical cross entropy 
cross entropy
adam

критерий качества нейронной сети

теория информации курс 
решающие деревья - энтропия и джини (критерии информативности)

EM на кирпичики
https://m.habr.com/ru/post/501850/

Метод максимального правдоподобия
Классические (частотные) и Баесовские подходы в теории вероятности - чем похожи и чем различаются?

# Алгоритмы на Pyth
https://www.youtube.com/watch?v=rLOyrWV8gmA&ab_channel=PythonEngineer


Почему L1 метрика это куб, а L2 круг?

learning_curve SKLEARN

Матрица ковариаций (первый собственный вектор)
сингулярное разложение

когда использовать DropOut?
При переобучении, и когда уменьшение нейронов не помогает

метод галвных компонент для агрегации коррелирующих данных ( мультикорелиарность) 

Репетитор:
* методы оптимизации (ньютона)
* баесовские методы
* метод главных компонент
* lca : неотрицательное матричное разложени 
* градиентный спуск
* цепи маркова
* неотрицательное матричное разложение
* собственный вектор и собсьвенное значение матрицы
* практика тер вер, производные и интегралы
* тригонометрия
* алгоритмы и структуры данных
* кореляция и ковариация 
* Выборочная дисперсия является смещённой оценкой теоретической дисперсии, а исправленная выборочная дисперсия — несмещённой:
https://ml-cheatsheet.readthedocs.io/en/latest/logistic_regression.html
https://ml-cheatsheet.readthedocs.io/en/latest/linear_regression.html
